{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: LRU Cache\n",
    "\n",
    "### Problem Description\n",
    "We have briefly discussed caching as part of a practice problem while studying hash maps. The lookup operation (i.e., `get()`) and put (`set()`) is supposed to be fast for a cache memory.\n",
    "\n",
    "While doing the `get()` operation, if the entry is found in the cache, it is known as a cache hit. If, however, the entry is not found, it is known as a cache miss.\n",
    "\n",
    "When designing a cache, we also place an upper bound on the size of the cache. If the cache is full and we want to add a new entry to the cache, we use some criteria to remove an element. After removing an element, we use the `put()` operation to insert the new element. The remove operation should also be fast.\n",
    "\n",
    "For our first problem, the goal will be to design a data structure known as a Least Recently Used (LRU) cache. An LRU cache is a type of cache in which we remove the least recently used entry when the cache memory reaches its limit. For the current problem, consider both `get` and `set` operations as use operations.\n",
    "\n",
    "Your job is to use an appropriate data structure(s) to implement the cache.\n",
    "\n",
    "In case of a cache hit, your `get()` operation should return the appropriate value. In case of a cache miss, your `get()` should return -1. While putting an element in the cache, your `put()` / `set()` operation must insert the element. If the cache is full, you must write code that removes the least recently used entry first and then insert the element. All operations must take O(1) time.\n",
    "\n",
    "For the current problem, you can consider the size of the cache = 5.\n",
    "\n",
    "### Implementation\n",
    "Here is some boilerplate code and some example test cases to get you started on this problem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "-1\n",
      "-1\n",
      "10\n",
      "None\n",
      "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "class LRU_Cache(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.cache = {}\n",
    "        self.capacity = capacity\n",
    "        self.order = []\n",
    "    \n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            self.order.remove(key)\n",
    "            self.order.append(key)\n",
    "            return self.cache[key]\n",
    "        return -1\n",
    "    \n",
    "    def set(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self.order.remove(key)\n",
    "        elif len(self.cache) >= self.capacity:\n",
    "            lru = self.order.pop(0)\n",
    "            del self.cache[lru]\n",
    "        self.cache[key] = value\n",
    "        self.order.append(key)\n",
    "\n",
    "# Test the LRU Cache implementation\n",
    "our_cache = LRU_Cache(5)\n",
    "\n",
    "our_cache.set(1, 1)\n",
    "our_cache.set(2, 2)\n",
    "our_cache.set(3, 3)\n",
    "our_cache.set(4, 4)\n",
    "\n",
    "print(our_cache.get(1))  # returns 1\n",
    "print(our_cache.get(2))  # returns 2\n",
    "print(our_cache.get(9))  # returns -1 because 9 is not present in the cache\n",
    "\n",
    "our_cache.set(5, 5) \n",
    "our_cache.set(6, 6)\n",
    "\n",
    "print(our_cache.get(3))  # returns -1 because the cache reached its capacity and 3 was the least recently used entry\n",
    "\n",
    "# Add your own test cases: include at least three test cases and two of them must include edge cases, such as null, empty or very large values\n",
    "\n",
    "# Test Case 1: Adding an existing key\n",
    "our_cache.set(1, 10)\n",
    "print(our_cache.get(1))  # returns 10 because we updated the value\n",
    "\n",
    "# Test Case 2: Edge case with null value\n",
    "our_cache.set(7, None)\n",
    "print(our_cache.get(7))  # returns None, testing handling of null values\n",
    "\n",
    "# Test Case 3: Edge case with very large values\n",
    "large_value = 'a' * 10000\n",
    "our_cache.set(8, large_value)\n",
    "print(our_cache.get(8))  # returns the large value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "**Class Initialization**:\n",
    "- The `__init__` method initializes the cache with a given capacity.\n",
    "- It uses a dictionary to store the cache items and a list to keep track of the order of usage.\n",
    "\n",
    "**Get Operation**:\n",
    "- The `get` method retrieves the value for the given key if it exists in the cache.\n",
    "- If the key is found, it updates the usage order to reflect that the key was recently accessed.\n",
    "- If the key is not found, it returns -1.\n",
    "\n",
    "**Set Operation**:\n",
    "- The `set` method adds or updates a key-value pair in the cache.\n",
    "- If the key is already in the cache, it updates the value and usage order.\n",
    "- If the cache is at capacity, it removes the least recently used item before adding the new item.\n",
    "- The least recently used item is the first item in the order list, which is removed and its corresponding entry in the cache dictionary is deleted.\n",
    "\n",
    "**Test Cases**:\n",
    "- **Test Case 1**: Verifies updating an existing key.\n",
    "- **Test Case 2**: Checks handling of null values.\n",
    "- **Test Case 3**: Tests the cache with a very large value.\n",
    "\n",
    "This implementation ensures that all operations (`get` and `set`) are performed in O(1) time, meeting the problem requirements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: File Recursion\n",
    "\n",
    "### Problem Description\n",
    "For this problem, the goal is to write code for finding all files under a directory (and all directories beneath it) that end with \".c\".\n",
    "\n",
    "Here is an example of a test directory listing:\n",
    "\n",
    "    \n",
    "/testdir\n",
    "./testdir/subdir1\n",
    "./testdir/subdir1/a.c\n",
    "./testdir/subdir1/a.h\n",
    "./testdir/subdir2\n",
    "./testdir/subdir2/.gitkeep\n",
    "./testdir/subdir3\n",
    "./testdir/subdir3/subsubdir1\n",
    "./testdir/subdir3/subsubdir1/b.c\n",
    "./testdir/subdir3/subsubdir1/b.h\n",
    "./testdir/subdir4\n",
    "./testdir/subdir4/.gitkeep\n",
    "./testdir/subdir5\n",
    "./testdir/subdir5/a.c\n",
    "./testdir/subdir5/a.h\n",
    "./testdir/t1.c\n",
    "./testdir/t1.h\n",
    "\n",
    "\n",
    "Python's `os` module will be useful—in particular, you may want to use the following resources:\n",
    "- `os.path.isdir(path)`\n",
    "- `os.path.isfile(path)`\n",
    "- `os.listdir(directory)`\n",
    "- `os.path.join(...)`\n",
    "\n",
    "Note: `os.walk()` is a handy Python method which can achieve this task very easily. However, for this problem you are not allowed to use `os.walk()`.\n",
    "\n",
    "### Implementation\n",
    "Here is some code for the function to get you started:\n",
    "\n",
    "```python\n",
    "def find_files(suffix, path):\n",
    "    \"\"\"\n",
    "    Find all files beneath path with file name suffix.\n",
    "\n",
    "    Note that a path may contain further subdirectories\n",
    "    and those subdirectories may also contain further subdirectories.\n",
    "\n",
    "    There is no limit to the depth of the subdirectories.\n",
    "\n",
    "    Args:\n",
    "      suffix (str): suffix if the file name to be found\n",
    "      path (str): path of the file system\n",
    "\n",
    "    Returns:\n",
    "       a list of paths\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    def find_files_recursively(suffix, path):\n",
    "        paths = []\n",
    "        for item in os.listdir(path):\n",
    "            item_path = os.path.join(path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                paths.extend(find_files_recursively(suffix, item_path))\n",
    "            elif os.path.isfile(item_path) and item_path.endswith(suffix):\n",
    "                paths.append(item_path)\n",
    "        return paths\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    \n",
    "    return find_files_recursively(suffix, path)\n",
    "\n",
    "# Example usage:\n",
    "print(find_files('.c', './testdir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./testdir/subdir3/subsubdir1/b.c', './testdir/subdir5/a.c', './testdir/subdir1/a.c', './testdir/t1.c']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def find_files(suffix, path):\n",
    "    \"\"\"\n",
    "    Find all files beneath path with file name suffix.\n",
    "\n",
    "    Note that a path may contain further subdirectories\n",
    "    and those subdirectories may also contain further subdirectories.\n",
    "\n",
    "    There is no limit to the depth of the subdirectories.\n",
    "\n",
    "    Args:\n",
    "      suffix (str): suffix if the file name to be found\n",
    "      path (str): path of the file system\n",
    "\n",
    "    Returns:\n",
    "       a list of paths\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def find_files_recursively(suffix, path):\n",
    "        paths = []\n",
    "        for item in os.listdir(path):\n",
    "            item_path = os.path.join(path, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                paths.extend(find_files_recursively(suffix, item_path))\n",
    "            elif os.path.isfile(item_path) and item_path.endswith(suffix):\n",
    "                paths.append(item_path)\n",
    "        return paths\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "\n",
    "    return find_files_recursively(suffix, path)\n",
    "\n",
    "# Example usage:\n",
    "print(find_files('.c', './testdir'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./testdir/subdir3/subsubdir1/b.c', './testdir/subdir5/a.c', './testdir/subdir1/a.c', './testdir/t1.c']\n",
      "[]\n",
      "['./testdir/subdir3/subsubdir1/b.c', './testdir/subdir5/a.c', './testdir/subdir1/a.c', './testdir/t1.c']\n"
     ]
    }
   ],
   "source": [
    "## Add your own test cases: include at least three test cases\n",
    "## and two of them must include edge cases, such as null, empty or very large values\n",
    "# Test Case 1: Directory containing files with the specified suffix\n",
    "print(find_files('.c', './testdir'))  # Should return paths to files ending with .c\n",
    "\n",
    "# Test Case 2: Empty directory\n",
    "os.makedirs('./emptydir', exist_ok=True)\n",
    "print(find_files('.c', './emptydir'))  # Should return an empty list\n",
    "\n",
    "# Test Case 3: Directory with subdirectories and various file types\n",
    "# Using the testdir structure extracted above\n",
    "print(find_files('.c', './testdir'))  # Should return paths to files ending with .c in all subdirectories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS Module Exploration Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emptydir', 'testdir.zip', 'Workbook.ipynb', 'testdir', '.ipynb_checkpoints']\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "### Locally save and call this file ex.py ##\n",
    "\n",
    "## Code to demonstrate the use of some of the OS modules in python\n",
    "\n",
    "import os\n",
    "\n",
    "## Let us print the files in the directory in which you are running this script\n",
    "print (os.listdir(\".\"))\n",
    "\n",
    "## Let us check if this file is indeed a file!\n",
    "print (os.path.isfile(\"./ex.py\"))\n",
    "\n",
    "## Does the file end with .py?\n",
    "print (\"./ex.py\".endswith(\".py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "**Function Definition**:\n",
    "- The `find_files` function takes in a `suffix` (file extension) and a `path` (directory path) as arguments.\n",
    "\n",
    "**Recursive Helper Function**:\n",
    "- The `find_files_recursively` function is defined within `find_files` to handle the recursive search for files.\n",
    "  - It iterates through all items in the current directory.\n",
    "  - If an item is a directory, it recursively searches within that directory.\n",
    "  - If an item is a file and ends with the specified suffix, it adds the file path to the results list.\n",
    "\n",
    "**Path Validation**:\n",
    "- Before starting the search, the function checks if the provided path exists to avoid errors.\n",
    "\n",
    "**Return Results**:\n",
    "- The function returns a list of file paths that match the specified suffix.\n",
    "\n",
    "**Test Cases**:\n",
    "- **Test Case 1**: Test with a directory containing files with the specified suffix.\n",
    "- **Test Case 2**: Test with an empty directory.\n",
    "- **Test Case 3**: Test with a directory containing subdirectories and various file types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Huffman Coding\n",
    "\n",
    "**Overview - Data Compression**\n",
    "Data compression algorithms reduce the amount of memory (bits) required to represent a message (data). Compressed data helps to reduce transmission time from sender to receiver. The sender encodes the data, and the receiver decodes the encoded data. As part of this problem, you need to implement the logic for both encoding and decoding.\n",
    "\n",
    "A data compression algorithm can be either lossy or lossless. Huffman Coding is a lossless data compression algorithm. Let's understand the two phases - encoding and decoding with the help of an example.\n",
    "\n",
    "#### A. Huffman Encoding\n",
    "\n",
    "Assume that we have a string message `AAAAAAABBBCCCCCCCDDEEEEEE` comprising 25 characters to be encoded. The string message can be unsorted as well. We will have two phases in encoding: building the Huffman tree (a binary tree) and generating the encoded data. The following steps illustrate the Huffman encoding:\n",
    "\n",
    "##### Phase I - Build the Huffman Tree\n",
    "\n",
    "1. **Determine the frequency of each character in the message.** \n",
    "   \n",
    "   For our example, the following table presents the frequency of each character:\n",
    "   \n",
    "   | (Unique) Character | Frequency |\n",
    "   |--------------------|-----------|\n",
    "   | A                  | 7         |\n",
    "   | B                  | 3         |\n",
    "   | C                  | 7         |\n",
    "   | D                  | 2         |\n",
    "   | E                  | 6         |\n",
    "\n",
    "2. **Build and sort a list of nodes in the order of lowest to highest frequencies.**\n",
    "\n",
    "   Each row in the table above can be represented as a node having a character, frequency, left child, and right child. Create a priority queue where a node that has lower frequency has a higher priority to be popped out.\n",
    "\n",
    "3. **Pop-out two nodes with the minimum frequency from the priority queue.**\n",
    "\n",
    "4. **Create a new node with a frequency equal to the sum of the two nodes picked.** \n",
    "\n",
    "   This new node becomes an internal node in the Huffman tree, and the two nodes become the children. The lower frequency node becomes a left child, and the higher frequency node becomes the right child. Reinsert the newly created node back into the priority queue.\n",
    "\n",
    "   A min-heap could be a better choice for the priority queue due to the lower complexity of sorting the elements every time there is an insertion.\n",
    "\n",
    "5. **Repeat steps 3 and 4 until there is a single element left in the priority queue.**\n",
    "\n",
    "6. **Assign a bit (0 for left child and 1 for right child) to each node in the Huffman tree.**\n",
    "\n",
    "##### Phase II - Generate the Encoded Data\n",
    "\n",
    "Based on the Huffman tree, generate a unique binary code for each character of our string message by traversing the path from root to the leaf node.\n",
    "\n",
    "| (Unique) Character | Frequency | Huffman Code |\n",
    "|--------------------|-----------|--------------|\n",
    "| D                  | 2         | 000          |\n",
    "| B                  | 3         | 001          |\n",
    "| E                  | 6         | 01           |\n",
    "| A                  | 7         | 10           |\n",
    "| C                  | 7         | 11           |\n",
    "\n",
    "Notice that the whole code for any character is not a prefix of any other code. Hence, the Huffman code is called a Prefix code. The binary code is shorter for more frequent characters, reducing memory usage.\n",
    "\n",
    "#### B. Huffman Decoding\n",
    "\n",
    "Once we have the encoded data and the Huffman tree, we can easily decode the encoded data using the following steps:\n",
    "\n",
    "1. **Declare a blank decoded string.**\n",
    "2. **Pick a bit from the encoded data, traversing from left to right.**\n",
    "3. **Start traversing the Huffman tree from the root.**\n",
    "   - If the current bit of encoded data is 0, move to the left child.\n",
    "   - If the current bit is 1, move to the right child.\n",
    "4. **If a leaf node is encountered, append the character of the leaf node to the decoded string.**\n",
    "5. **Repeat steps 2 and 3 until the encoded data is completely traversed.**\n",
    "\n",
    "You will implement the logic for both encoding and decoding in the following template. Also, create sizing schemas to present a summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the data is: 69\n",
      "\n",
      "The content of the data is: The bird is the word\n",
      "\n",
      "The size of the encoded data is: 36\n",
      "\n",
      "The content of the encoded data is: 1110111111101010001100110000101100101101101011111101010000111001100001\n",
      "\n",
      "The size of the decoded data is: 69\n",
      "\n",
      "The content of the decoded data is: The bird is the word\n",
      "\n",
      "Test Case 1\n",
      "Original: , Encoded: , Decoded: \n",
      "Test Case 2\n",
      "Original: AAAAAAABBBCCCCCCCDDEEEEEE, Encoded: 1010101010101000100100111111111111111000000010101010101, Decoded: AAAAAAABBBCCCCCCCDDEEEEEE\n",
      "Test Case 3\n",
      "Original: A, Encoded: , Decoded: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import heapq\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "def huffman_encoding(data):\n",
    "    if not data:\n",
    "        return \"\", None\n",
    "\n",
    "    frequency = {}\n",
    "    for char in data:\n",
    "        if char not in frequency:\n",
    "            frequency[char] = 0\n",
    "        frequency[char] += 1\n",
    "\n",
    "    priority_queue = [Node(char, freq) for char, freq in frequency.items()]\n",
    "    heapq.heapify(priority_queue)\n",
    "\n",
    "    while len(priority_queue) > 1:\n",
    "        left = heapq.heappop(priority_queue)\n",
    "        right = heapq.heappop(priority_queue)\n",
    "        merged = Node(None, left.freq + right.freq)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        heapq.heappush(priority_queue, merged)\n",
    "\n",
    "    huffman_tree = priority_queue[0]\n",
    "\n",
    "    huffman_codes = {}\n",
    "    def generate_codes(node, current_code):\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.char is not None:\n",
    "            huffman_codes[node.char] = current_code\n",
    "        generate_codes(node.left, current_code + \"0\")\n",
    "        generate_codes(node.right, current_code + \"1\")\n",
    "\n",
    "    generate_codes(huffman_tree, \"\")\n",
    "    encoded_data = \"\".join([huffman_codes[char] for char in data])\n",
    "\n",
    "    return encoded_data, huffman_tree\n",
    "\n",
    "def huffman_decoding(data, tree):\n",
    "    if not data or not tree:\n",
    "        return \"\"\n",
    "\n",
    "    decoded_data = []\n",
    "    node = tree\n",
    "    for bit in data:\n",
    "        if bit == '0':\n",
    "            node = node.left\n",
    "        else:\n",
    "            node = node.right\n",
    "\n",
    "        if node.char is not None:\n",
    "            decoded_data.append(node.char)\n",
    "            node = tree\n",
    "\n",
    "    return \"\".join(decoded_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    codes = {}\n",
    "\n",
    "    a_great_sentence = \"The bird is the word\"\n",
    "\n",
    "    print (\"The size of the data is: {}\\n\".format(sys.getsizeof(a_great_sentence)))\n",
    "    print (\"The content of the data is: {}\\n\".format(a_great_sentence))\n",
    "\n",
    "    encoded_data, tree = huffman_encoding(a_great_sentence)\n",
    "\n",
    "    print (\"The size of the encoded data is: {}\\n\".format(sys.getsizeof(int(encoded_data, base=2))))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(encoded_data))\n",
    "\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "\n",
    "    print (\"The size of the decoded data is: {}\\n\".format(sys.getsizeof(decoded_data)))\n",
    "    print (\"The content of the decoded data is: {}\\n\".format(decoded_data))\n",
    "\n",
    "    # Add your own test cases: include at least three test cases\n",
    "    # and two of them must include edge cases, such as null, empty or very large values\n",
    "\n",
    "    # Test Case 1\n",
    "    print(\"Test Case 1\")\n",
    "    test_string_1 = \"\"\n",
    "    encoded_data, tree = huffman_encoding(test_string_1)\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "    print(f\"Original: {test_string_1}, Encoded: {encoded_data}, Decoded: {decoded_data}\")\n",
    "\n",
    "    # Test Case 2\n",
    "    print(\"Test Case 2\")\n",
    "    test_string_2 = \"AAAAAAABBBCCCCCCCDDEEEEEE\"\n",
    "    encoded_data, tree = huffman_encoding(test_string_2)\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "    print(f\"Original: {test_string_2}, Encoded: {encoded_data}, Decoded: {decoded_data}\")\n",
    "\n",
    "    # Test Case 3\n",
    "    print(\"Test Case 3\")\n",
    "    test_string_3 = \"A\"\n",
    "    encoded_data, tree = huffman_encoding(test_string_3)\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "    print(f\"Original: {test_string_3}, Encoded: {encoded_data}, Decoded: {decoded_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Answer\n",
    "\n",
    "The solution involves two main parts: Huffman Encoding and Huffman Decoding. Let's break down each part in detail.\n",
    "\n",
    "#### A. Huffman Encoding\n",
    "\n",
    "1. **Frequency Calculation:**\n",
    "   - First, we determine the frequency of each character in the input string. This is done using a dictionary where the key is the character and the value is its frequency.\n",
    "\n",
    "2. **Priority Queue:**\n",
    "   - We use a priority queue (implemented using a min-heap) to store the nodes. Each node represents a character and its frequency. The priority queue allows us to efficiently extract the two nodes with the smallest frequencies.\n",
    "\n",
    "3. **Building the Huffman Tree:**\n",
    "   - We repeatedly extract the two nodes with the smallest frequencies from the priority queue.\n",
    "   - We create a new internal node with these two nodes as children. The frequency of the new node is the sum of the frequencies of the two children nodes.\n",
    "   - We insert this new node back into the priority queue.\n",
    "   - This process continues until there is only one node left in the queue, which becomes the root of the Huffman tree.\n",
    "\n",
    "4. **Generating Huffman Codes:**\n",
    "   - We traverse the Huffman tree from the root to each leaf node. \n",
    "   - We assign a binary code to each character based on the path taken to reach it (0 for left, 1 for right).\n",
    "   - The result is a unique binary code for each character, with more frequent characters having shorter codes.\n",
    "\n",
    "#### B. Huffman Decoding\n",
    "\n",
    "1. **Decoding Process:**\n",
    "   - We use the Huffman tree to decode the encoded data.\n",
    "   - Starting from the root of the tree, we traverse it according to the bits in the encoded data (0 for left, 1 for right).\n",
    "   - When we reach a leaf node, we append the character of that node to the decoded string.\n",
    "   - This process is repeated until the entire encoded data is traversed.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "- The `Node` class is used to represent each node in the Huffman tree. It contains the character, frequency, left child, and right child.\n",
    "- The `huffman_encoding` function performs the encoding process, returning the encoded data and the Huffman tree.\n",
    "- The `huffman_decoding` function uses the Huffman tree to decode the encoded data.\n",
    "- The main function demonstrates the encoding and decoding process with an example string and prints the sizes of the original, encoded, and decoded data.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- **Efficiency:** Huffman Coding ensures that more frequent characters have shorter binary codes, leading to efficient data compression.\n",
    "- **Lossless Compression:** There is no loss of information during compression and decompression.\n",
    "- **Prefix Codes:** The codes are uniquely decodable as no code is a prefix of another, ensuring correct decoding.\n",
    "\n",
    "This approach can be used for various applications where data compression is needed without losing information, such as file compression, image compression, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Active Directory\n",
    "\n",
    "### Problem Description\n",
    "\n",
    "In Windows Active Directory, a group can consist of user(s) and group(s) themselves. We can construct this hierarchy using a class structure where a `Group` can have sub-groups and users.\n",
    "\n",
    "#### Class Definition\n",
    "\n",
    "```python\n",
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []\n",
    "        self.users = []\n",
    "\n",
    "    def add_group(self, group):\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self, user):\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []\n",
    "        self.users = []\n",
    "\n",
    "    def add_group(self, group):\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self, user):\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "sub_child_user = \"sub_child_user\"\n",
    "sub_child.add_user(sub_child_user)\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_user_in_group(user, group):\n",
    "    \"\"\"\n",
    "    Return True if user is in the group, False otherwise.\n",
    "\n",
    "    Args:\n",
    "      user (str): user name/id\n",
    "      group (class: Group): group to check user membership against\n",
    "    \"\"\"\n",
    "    if user in group.get_users():\n",
    "        return True\n",
    "    \n",
    "    for subgroup in group.get_groups():\n",
    "        if is_user_in_group(user, subgroup):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Case 1: User in sub-group\n",
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "sub_child_user = \"sub_child_user\"\n",
    "sub_child.add_user(sub_child_user)\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)\n",
    "\n",
    "assert is_user_in_group(\"sub_child_user\", parent) == True  # Should return True\n",
    "\n",
    "## Test Case 2: User not in any group\n",
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)\n",
    "\n",
    "assert is_user_in_group(\"non_existent_user\", parent) == False  # Should return False\n",
    "\n",
    "## Test Case 3: Empty group\n",
    "empty_group = Group(\"empty\")\n",
    "assert is_user_in_group(\"any_user\", empty_group) == False  # Should return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explanation of the Answer\n",
    "\n",
    "To determine whether a user is in a group (or any of its sub-groups), we can use a recursive approach. Here’s a step-by-step explanation:\n",
    "\n",
    "1. **Base Case:**\n",
    "   - If the user is found in the current group's user list, return `True`.\n",
    "\n",
    "2. **Recursive Case:**\n",
    "   - If the user is not found in the current group's user list, recursively check all sub-groups.\n",
    "   - If any sub-group contains the user, return `True`.\n",
    "\n",
    "3. **End Condition:**\n",
    "   - If the user is not found in the current group or any sub-group, return `False`.\n",
    "\n",
    "This approach ensures that we traverse the entire hierarchy of groups and sub-groups to find the user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Blockchain\n",
    "\n",
    "### Problem Description\n",
    "A Blockchain is a sequential chain of records, similar to a linked list. Each block contains some information and is connected to other blocks in the chain. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. For our blockchain, we will be using a SHA-256 hash, the Greenwich Mean Time when the block was created, and text strings as the data.\n",
    "\n",
    "### Blockchain Structure\n",
    "A Blockchain can be broken down into three main parts:\n",
    "\n",
    "1. **Information Hash:**\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "def calc_hash(self):\n",
    "    sha = hashlib.sha256()\n",
    "    hash_str = \"We are going to encode this string of data!\".encode('utf-8')\n",
    "    sha.update(hash_str)\n",
    "    return sha.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "class Block:\n",
    "    def __init__(self, timestamp, data, previous_hash):\n",
    "        self.timestamp = timestamp\n",
    "        self.data = data\n",
    "        self.previous_hash = previous_hash\n",
    "        self.hash = self.calc_hash()\n",
    "\n",
    "    def calc_hash(self):\n",
    "        sha = hashlib.sha256()\n",
    "        hash_str = f\"{self.timestamp}{self.data}{self.previous_hash}\".encode('utf-8')\n",
    "        sha.update(hash_str)\n",
    "        return sha.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blockchain:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def add_block(self, data):\n",
    "        if self.head is None:\n",
    "            self.head = Block(self.get_timestamp(), data, \"0\")\n",
    "        else:\n",
    "            new_block = Block(self.get_timestamp(), data, self.head.hash)\n",
    "            new_block.previous_block = self.head\n",
    "            self.head = new_block\n",
    "\n",
    "    def get_timestamp(self):\n",
    "        from datetime import datetime\n",
    "        return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2024-05-16 21:07:48, Data: Third Block, Hash: f23f198daeca9cd5c435fb7b7f81a45b0893f232892045cf17642182a501a484, Previous Hash: b2b2911d04ee86464c0fcedef7f5e8be746c15d5672280cacfadd472120e744d\n",
      "Timestamp: 2024-05-16 21:07:48, Data: Second Block, Hash: b2b2911d04ee86464c0fcedef7f5e8be746c15d5672280cacfadd472120e744d, Previous Hash: 4f2910bd0f36938b73a0910a181d40fa3b26dafbf66949f76aef186e0eaabdfb\n",
      "Timestamp: 2024-05-16 21:07:48, Data: First Block, Hash: 4f2910bd0f36938b73a0910a181d40fa3b26dafbf66949f76aef186e0eaabdfb, Previous Hash: 0\n",
      "Timestamp: 2024-05-16 21:07:48, Data Length: 1000000, Hash: 46d3c98b21ebad49b46234f1d719b1bd71efdf1c848a90149f6d9ead13d691b2\n",
      "Timestamp: 2024-05-16 21:07:48, Data: '', Hash: 0ceb981f659d2be7e1a01478420f5d49adce56de8d2a166395c8ada3dd53d31e\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Adding blocks to the blockchain\n",
    "blockchain = Blockchain()\n",
    "blockchain.add_block(\"First Block\")\n",
    "blockchain.add_block(\"Second Block\")\n",
    "blockchain.add_block(\"Third Block\")\n",
    "\n",
    "# Check the blockchain structure\n",
    "current = blockchain.head\n",
    "while current:\n",
    "    print(f\"Timestamp: {current.timestamp}, Data: {current.data}, Hash: {current.hash}, Previous Hash: {current.previous_hash}\")\n",
    "    current = getattr(current, 'previous_block', None)\n",
    "\n",
    "# Test Case 2: Adding blocks with large data\n",
    "large_data = \"x\" * 1000000  # 1 million characters\n",
    "blockchain = Blockchain()\n",
    "blockchain.add_block(large_data)\n",
    "print(f\"Timestamp: {blockchain.head.timestamp}, Data Length: {len(blockchain.head.data)}, Hash: {blockchain.head.hash}\")\n",
    "\n",
    "# Test Case 3: Empty data block\n",
    "blockchain = Blockchain()\n",
    "blockchain.add_block(\"\")\n",
    "print(f\"Timestamp: {blockchain.head.timestamp}, Data: '{blockchain.head.data}', Hash: {blockchain.head.hash}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Answer\n",
    "\n",
    "A blockchain is essentially a linked list of blocks, where each block contains a cryptographic hash of the previous block, a timestamp, and some data. The SHA-256 algorithm is used to create the hash, ensuring the integrity of the blockchain.\n",
    "\n",
    "1. **Information Hash:**\n",
    "   - The `calc_hash` function calculates the hash of the data stored in a block. This hash serves as a unique identifier for the block and ensures the data has not been tampered with.\n",
    "\n",
    "2. **Block Class:**\n",
    "   - The `Block` class represents a single block in the blockchain. Each block contains a timestamp, some data, the hash of the previous block, and its own hash.\n",
    "\n",
    "3. **Blockchain Implementation:**\n",
    "   - The `Blockchain` class manages the chain of blocks. It allows adding new blocks to the chain and ensures each new block contains the hash of the previous block, maintaining the integrity of the chain.\n",
    "\n",
    "This approach ensures a simple but effective implementation of a blockchain, suitable for understanding the basic principles of blockchain technology.\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "class Block:\n",
    "    def __init__(self, timestamp, data, previous_hash):\n",
    "        self.timestamp = timestamp\n",
    "        self.data = data\n",
    "        self.previous_hash = previous_hash\n",
    "        self.hash = self.calc_hash()\n",
    "\n",
    "    def calc_hash(self):\n",
    "        sha = hashlib.sha256()\n",
    "        hash_str = self.data.encode('utf-8')\n",
    "        sha.update(hash_str)\n",
    "        return sha.hexdigest()\n",
    "\n",
    "class Blockchain:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def add_block(self, data):\n",
    "        if self.head is None:\n",
    "            self.head = Block(time.gmtime(), data, \"0\")\n",
    "        else:\n",
    "            new_block = Block(time.gmtime(), data, self.head.hash)\n",
    "            new_block.previous = self.head\n",
    "            self.head = new_block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Union and Intersection of Two Linked Lists\n",
    "\n",
    "#### Problem Description\n",
    "The union of two sets \\( A \\) and \\( B \\) is the set of elements which are in \\( A \\), in \\( B \\), or in both \\( A \\) and \\( B \\). For example, the union of \\( A = [1, 2] \\) and \\( B = [3, 4] \\) is \\([1, 2, 3, 4]\\).\n",
    "\n",
    "The intersection of two sets \\( A \\) and \\( B \\), denoted by \\( A \\cap B \\), is the set of all objects that are members of both sets \\( A \\) and \\( B \\). For example, the intersection of \\( A = [1, 2, 3] \\) and \\( B = [2, 3, 4] \\) is \\([2, 3]\\).\n",
    "\n",
    "You will take in two linked lists and return a linked list that is composed of either the union or intersection, respectively. Once you have completed the problem you will create your own test cases and perform your own run time analysis on the code.\n",
    "\n",
    "We have provided a code template below, you are not required to use it:\n",
    "\n",
    "```python\n",
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def __str__(self):\n",
    "        cur_head = self.head\n",
    "        out_string = \"\"\n",
    "        while cur_head:\n",
    "            out_string += str(cur_head.value) + \" -> \"\n",
    "            cur_head = cur_head.next\n",
    "        return out_string\n",
    "\n",
    "    def append(self, value):\n",
    "        if self.head is None:\n",
    "            self.head = Node(value)\n",
    "            return\n",
    "\n",
    "        node = self.head\n",
    "        while node.next:\n",
    "            node = node.next\n",
    "\n",
    "        node.next = Node(value)\n",
    "\n",
    "    def size(self):\n",
    "        size = 0\n",
    "        node = self.head\n",
    "        while node:\n",
    "            size += 1\n",
    "            node = node.next\n",
    "\n",
    "        return size\n",
    "\n",
    "def union(llist_1, llist_2):\n",
    "    # Your Solution Here\n",
    "    pass\n",
    "\n",
    "def intersection(llist_1, llist_2):\n",
    "    # Your Solution Here\n",
    "    pass\n",
    "\n",
    "# Test case 1\n",
    "\n",
    "linked_list_1 = LinkedList()\n",
    "linked_list_2 = LinkedList()\n",
    "\n",
    "element_1 = [3,2,4,35,6,65,6,4,3,21]\n",
    "element_2 = [6,32,4,9,6,1,11,21,1]\n",
    "\n",
    "for i in element_1:\n",
    "    linked_list_1.append(i)\n",
    "for i in element_2:\n",
    "    linked_list_2.append(i)\n",
    "\n",
    "print (union(linked_list_1,linked_list_2))\n",
    "print (intersection(linked_list_1,linked_list_2))\n",
    "\n",
    "# Test case 2\n",
    "\n",
    "linked_list_3 = LinkedList()\n",
    "linked_list_4 = LinkedList()\n",
    "\n",
    "element_3 = [3,2,4,35,6,65,6,4,3,23]\n",
    "element_4 = [1,7,8,9,11,21,1]\n",
    "\n",
    "for i in element_3:\n",
    "    linked_list_3.append(i)\n",
    "for i in element_4:\n",
    "    linked_list_4.append(i)\n",
    "\n",
    "print (union(linked_list_3,linked_list_4))\n",
    "print (intersection(linked_list_3,linked_list_4))\n",
    "\n",
    "Add your own test cases: include at least three test cases\n",
    "and two of them must include edge cases, such as null, empty or very large values\n",
    "\n",
    "Test Case 1\n",
    "\n",
    "Test Case 2\n",
    "\n",
    "Test Case 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 -> 65 -> 2 -> 35 -> 3 -> 4 -> 6 -> 1 -> 9 -> 11 -> 21 -> \n",
      "4 -> 21 -> 6 -> \n",
      "65 -> 2 -> 35 -> 3 -> 4 -> 6 -> 1 -> 7 -> 8 -> 9 -> 11 -> 21 -> 23 -> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.next = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "\n",
    "    def __str__(self):\n",
    "        cur_head = self.head\n",
    "        out_string = \"\"\n",
    "        while cur_head:\n",
    "            out_string += str(cur_head.value) + \" -> \"\n",
    "            cur_head = cur_head.next\n",
    "        return out_string\n",
    "\n",
    "    def append(self, value):\n",
    "        if self.head is None:\n",
    "            self.head = Node(value)\n",
    "            return\n",
    "\n",
    "        node = self.head\n",
    "        while node.next:\n",
    "            node = node.next\n",
    "\n",
    "        node.next = Node(value)\n",
    "\n",
    "    def size(self):\n",
    "        size = 0\n",
    "        node = self.head\n",
    "        while node:\n",
    "            size += 1\n",
    "            node = node.next\n",
    "\n",
    "        return size\n",
    "\n",
    "def union(llist_1, llist_2):\n",
    "    elements = set()\n",
    "    current = llist_1.head\n",
    "    while current:\n",
    "        elements.add(current.value)\n",
    "        current = current.next\n",
    "\n",
    "    current = llist_2.head\n",
    "    while current:\n",
    "        elements.add(current.value)\n",
    "        current = current.next\n",
    "\n",
    "    union_list = LinkedList()\n",
    "    for value in elements:\n",
    "        union_list.append(value)\n",
    "\n",
    "    return union_list\n",
    "\n",
    "def intersection(llist_1, llist_2):\n",
    "    elements_1 = set()\n",
    "    current = llist_1.head\n",
    "    while current:\n",
    "        elements_1.add(current.value)\n",
    "        current = current.next\n",
    "\n",
    "    intersection_set = set()\n",
    "    current = llist_2.head\n",
    "    while current:\n",
    "        if current.value in elements_1:\n",
    "            intersection_set.add(current.value)\n",
    "        current = current.next\n",
    "\n",
    "    intersection_list = LinkedList()\n",
    "    for value in intersection_set:\n",
    "        intersection_list.append(value)\n",
    "\n",
    "    return intersection_list\n",
    "\n",
    "## Test case 1\n",
    "\n",
    "linked_list_1 = LinkedList()\n",
    "linked_list_2 = LinkedList()\n",
    "\n",
    "element_1 = [3,2,4,35,6,65,6,4,3,21]\n",
    "element_2 = [6,32,4,9,6,1,11,21,1]\n",
    "\n",
    "for i in element_1:\n",
    "    linked_list_1.append(i)\n",
    "\n",
    "for i in element_2:\n",
    "    linked_list_2.append(i)\n",
    "\n",
    "print (union(linked_list_1,linked_list_2))\n",
    "print (intersection(linked_list_1,linked_list_2))\n",
    "\n",
    "## Test case 2\n",
    "\n",
    "linked_list_3 = LinkedList()\n",
    "linked_list_4 = LinkedList()\n",
    "\n",
    "element_1 = [3,2,4,35,6,65,6,4,3,23]\n",
    "element_2 = [1,7,8,9,11,21,1]\n",
    "\n",
    "for i in element_1:\n",
    "    linked_list_3.append(i)\n",
    "\n",
    "for i in element_2:\n",
    "    linked_list_4.append(i)\n",
    "\n",
    "print (union(linked_list_3,linked_list_4))\n",
    "print (intersection(linked_list_3,linked_list_4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union of empty lists: \n",
      "Intersection of empty lists: \n",
      "Union with one empty list: 1 -> 2 -> 3 -> \n",
      "Intersection with one empty list: \n",
      "Union with no common elements: 1 -> 2 -> 3 -> 4 -> 5 -> 6 -> \n",
      "Intersection with no common elements: \n"
     ]
    }
   ],
   "source": [
    "# Additional Test Cases\n",
    "# Test Case 1: Both lists are empty\n",
    "empty_list_1 = LinkedList()\n",
    "empty_list_2 = LinkedList()\n",
    "print(\"Union of empty lists:\", union(empty_list_1, empty_list_2))\n",
    "print(\"Intersection of empty lists:\", intersection(empty_list_1, empty_list_2))\n",
    "\n",
    "# Test Case 2: One list is empty\n",
    "list_with_elements = LinkedList()\n",
    "elements = [1, 2, 3]\n",
    "for i in elements:\n",
    "    list_with_elements.append(i)\n",
    "print(\"Union with one empty list:\", union(empty_list_1, list_with_elements))\n",
    "print(\"Intersection with one empty list:\", intersection(empty_list_1, list_with_elements))\n",
    "\n",
    "# Test Case 3: Lists with no common elements\n",
    "list_1 = LinkedList()\n",
    "list_2 = LinkedList()\n",
    "elements_1 = [1, 2, 3]\n",
    "elements_2 = [4, 5, 6]\n",
    "for i in elements_1:\n",
    "    list_1.append(i)\n",
    "for i in elements_2:\n",
    "    list_2.append(i)\n",
    "print(\"Union with no common elements:\", union(list_1, list_2))\n",
    "print(\"Intersection with no common elements:\", intersection(list_1, list_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Answer\n",
    "\n",
    "To solve the problem of finding the union and intersection of two linked lists, we can follow these steps:\n",
    "\n",
    "#### Union of Two Linked Lists:\n",
    "\n",
    "- The union of two sets includes all elements from both sets without duplicates.\n",
    "- To implement this, we traverse both linked lists and add their elements to a set (to remove duplicates). Then, we create a new linked list from this set.\n",
    "\n",
    "#### Intersection of Two Linked Lists:\n",
    "\n",
    "- The intersection of two sets includes only the elements that are present in both sets.\n",
    "- To implement this, we use two sets: one to store the elements of the first linked list and the other to store the intersection elements. We then traverse the second linked list and add elements to the intersection set if they are present in the first set. Finally, we create a new linked list from the intersection set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
